{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54c1d681-c211-4b0b-8e57-929b9333e41f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade numpy gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfdba69a-39af-4a29-a657-8cd34311f14d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    return [token for token in simple_preprocess(sentence) if token not in STOPWORDS]\n",
    "\n",
    "def LDA_topic(sentence):\n",
    "    sentence_bow = dictionary.doc2bow(sentence)\n",
    "    topic_probabilities = lda_model.get_document_topics(sentence_bow)\n",
    "    topic_index_with_highest_prob = max(topic_probabilities, key=lambda x: x[1])[0]\n",
    "    return topic_index_with_highest_prob + 1\n",
    "\n",
    "def concatenate_reviews(df, max_char_length):\n",
    "    dataframe = df.rename(columns={\"ldatopic\": \"topic\", \"conwords\": \"words\"})\n",
    "    dataframe = dataframe.sort_values(by=['date', 'topic'])\n",
    "    concatenated_data = {'concatenated_string': [], 'start_time': [], 'end_time': [], 'topic': []}\n",
    "    current_concatenated_str = ''\n",
    "    current_start_time = None\n",
    "    current_end_time = None\n",
    "    current_topic = None\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if current_topic is None:\n",
    "            current_topic = row['topic']\n",
    "            current_start_time = row['date']\n",
    "            current_end_time = row['date']\n",
    "            current_concatenated_str = row['words']\n",
    "        else:\n",
    "            if current_topic == row['topic'] and len(current_concatenated_str) + len(row['words']) <= max_char_length:\n",
    "                current_concatenated_str += ' ' + row['words']\n",
    "                current_end_time = row['date']\n",
    "            else:\n",
    "                concatenated_data['concatenated_string'].append(current_concatenated_str)\n",
    "                concatenated_data['start_time'].append(current_start_time)\n",
    "                concatenated_data['end_time'].append(current_end_time)\n",
    "                concatenated_data['topic'].append(current_topic)\n",
    "                \n",
    "                current_topic = row['topic']\n",
    "                current_start_time = row['date']\n",
    "                current_end_time = row['date']\n",
    "                current_concatenated_str = row['words']\n",
    "\n",
    "    concatenated_data['concatenated_string'].append(current_concatenated_str)\n",
    "    concatenated_data['start_time'].append(current_start_time)\n",
    "    concatenated_data['end_time'].append(current_end_time)\n",
    "    concatenated_data['topic'].append(current_topic)\n",
    "    concatenated_df = pd.DataFrame(concatenated_data)\n",
    "    concatenated_df['SMonth'] = concatenated_df['start_time'].dt.month \n",
    "    concatenated_df['EMonth'] = concatenated_df['end_time'].dt.month \n",
    "    return concatenated_df\n",
    "\n",
    "def concat_more(concatenated_df, max_length, str_col = 'concatenated_string', first = False):\n",
    "    newstrings = []\n",
    "    newstart = []\n",
    "    newend = []\n",
    "    newtopic = []\n",
    "    newind = []\n",
    "    for a in list(concatenated_df['topic'].unique()):\n",
    "        if first:\n",
    "            topicdf = concatenated_df[concatenated_df['topic'] == a].sort_values(by=['date'])\n",
    "            indices = topicdf['index'].tolist()\n",
    "            # print(indices)\n",
    "            # break\n",
    "            strings = topicdf[str_col].tolist()\n",
    "            start = topicdf['date'].tolist()\n",
    "            end = topicdf['date'].tolist()\n",
    "        else:\n",
    "            topicdf = concatenated_df[concatenated_df['topic'] == a].sort_values(by=['start_time'])\n",
    "            indices = topicdf['index'].tolist()\n",
    "            # print(indices)\n",
    "            # break\n",
    "            strings = topicdf[str_col].tolist()\n",
    "            start = topicdf['start_time'].tolist()\n",
    "            end = topicdf['end_time'].tolist()\n",
    "        skip = []\n",
    "        \n",
    "        for i in range(len(strings)-1):\n",
    "            statement = False\n",
    "            if i not in skip:\n",
    "                temp = strings[i] + \" \\n\" + strings[i+1]\n",
    "                temp = temp.replace(\"Continue reading\", \"\\n\")\n",
    "                if len(temp) < max_length and end[i + 1].year==start[i].year:\n",
    "                    if end[i + 1] < end[i]:\n",
    "                        print(end[i + 1], end[i])\n",
    "                    newstrings.append(temp)\n",
    "                    newind.append(indices[i] + indices[i+1])\n",
    "                    newend.append(end[i + 1])\n",
    "                    newstart.append(start[i])\n",
    "                    newtopic.append(a)\n",
    "                    skip.append(i+1)\n",
    "                    statement = True\n",
    "                else:\n",
    "                    newstrings.append(temp)\n",
    "                    newend.append(end[i])\n",
    "                    newstart.append(start[i])\n",
    "                    newtopic.append(a)\n",
    "                    newind.append(indices[i])\n",
    "\n",
    "    if statement:\n",
    "        return concat_more(pd.DataFrame({\"index\":newind, \"concatenated_string\": newstrings, \"start_time\": newstart, \"end_time\": newend, \"topic\": newtopic}), max_length)\n",
    "    return pd.DataFrame({\"index\":newind,\"concatenated_string\": newstrings, \"start_time\": newstart, \"end_time\": newend, \"topic\": newtopic})\n",
    "\n",
    "def ind2list(ind):\n",
    "    return [ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d74d9f-24a0-4b1f-a57c-24a0b540c602",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/lichengrui/glassdoor_scraping/main/data.csv\"\n",
    "df=pd.read_csv(url)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df = df.dropna(how='all')\n",
    "df['date'] = pd.to_datetime(df['date']) \n",
    "df['processed_conwords'] = df['conwords'].apply(preprocess_sentence)\n",
    "\n",
    "dictionary = corpora.Dictionary(df['processed_conwords'])\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in df['processed_conwords']]\n",
    "\n",
    "num_topics = 10  # Set the number of topics\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "df['topic'] = df['processed_conwords'].apply(LDA_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23171bb6-ec83-4a79-8e80-28de6065be10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e087a5b7-f3fb-4c09-87b0-668ab4b78452",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "max_length = 300\n",
    "result_df = df.reset_index()\n",
    "result_df['index'] = result_df['index'].apply(ind2list)\n",
    "result_df = concat_more(result_df, max_length, \"conwords\", True)\n",
    "result_df1 = concat_more(result_df.sort_values(by=['start_time']),max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d1aa4aa-4cac-4947-9bf2-d10a4a08b7a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed02e1a9-2038-48ad-98c7-b90efb26c40a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summary(review):\n",
    "    return summarizer(review, max_length=130, min_length=10, do_sample=False)[0][\"summary_text\"]\n",
    "testdf = result_df.head(50)\n",
    "testdf['summarized'] = testdf['concatenated_string'].apply(summary)\n",
    "display(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec3932a7-1833-4738-8fc5-cb603b0e2170",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def build_review_tree(data_df):\n",
    "    review_tree = {\n",
    "                \"name\": \"Root\", \n",
    "                \"children\": []}\n",
    "\n",
    "    for _, row in data_df.iterrows():\n",
    "        date = pd.to_datetime(row['date'])\n",
    "        year = date.year\n",
    "        rating = row['rating']\n",
    "        review = row['conwords']\n",
    "        topic = row['topic']\n",
    "\n",
    "\n",
    "        # Create rating node if not present\n",
    "        appendyear = True\n",
    "        appendrating = True\n",
    "        appendtopic = True\n",
    "        for j in range(len(review_tree[\"children\"])):\n",
    "            if review_tree[\"children\"][j][\"year\"] == year:\n",
    "                appendyear = False\n",
    "                break\n",
    "        if appendyear:\n",
    "            review_tree[\"children\"].append({\n",
    "                \"year\": year,\n",
    "                \"name\": \"Year: \" + str(year), \n",
    "                \"children\": [{\n",
    "                    \"rating\": rating,\n",
    "                    \"name\": \"Rating: \" + str(rating), \n",
    "                    \"children\": [{\n",
    "                        \"topic\": topic,\n",
    "                        \"name\": \"Topic: \" + str(topic), \n",
    "                        \"children\": [{\n",
    "                            'name': review,\n",
    "                        }]}]}]})\n",
    "        else:\n",
    "            for i in range(len(review_tree[\"children\"][j][\"children\"])):\n",
    "                 if review_tree[\"children\"][j][\"children\"][i][\"rating\"] == rating:\n",
    "                     appendrating = False\n",
    "                     break\n",
    "            if appendrating:\n",
    "                review_tree[\"children\"][j][\"children\"].append({\n",
    "                    \"rating\": rating,\n",
    "                    \"name\": \"Rating: \" + str(rating), \n",
    "                    \"children\": [{\n",
    "                        \"topic\": topic,\n",
    "                        \"name\": \"Topic: \" + str(topic), \n",
    "                        \"children\": [{\n",
    "                            'name': review,\n",
    "                        }]}]})\n",
    "            else:\n",
    "                for k in range(len(review_tree[\"children\"][j][\"children\"][i][\"children\"])):\n",
    "                    if review_tree[\"children\"][j][\"children\"][i][\"children\"][k][\"topic\"] == topic:\n",
    "                        appendtopic = False\n",
    "                        break\n",
    "                if appendtopic:\n",
    "                    review_tree[\"children\"][j][\"children\"][i]['children'].append({\n",
    "                        \"topic\": topic,\n",
    "                        \"name\": \"Topic: \" + str(topic), \n",
    "                        \"children\": [{\n",
    "                            'name': review,\n",
    "                        }]})\n",
    "                else:\n",
    "                    review_tree[\"children\"][j][\"children\"][i][\"children\"][k]['children'].append({\n",
    "                            'name': review,\n",
    "                        })\n",
    "    return review_tree\n",
    "\n",
    "def moreNodes(lst,max_length, p = False):\n",
    "    if p:\n",
    "        print(\"INPUT LIST\")\n",
    "        print(lst)\n",
    "    length = 0\n",
    "    newstring = \"\"\n",
    "    children = []\n",
    "    notadded=True\n",
    "    node = {\"name\": 'placeholder', \"children\": []}\n",
    "    for count in range(len(lst)):\n",
    "        assert type(lst[count]==dict)\n",
    "        currentReview = lst[count]['name']\n",
    "        if len(currentReview) > max_length:\n",
    "            node['name'] = summary(newstring)\n",
    "            children.append(node)\n",
    "            children.append({\"name\": summary(currentReview), \"children\": [lst[count]]})\n",
    "            node = {\"name\": 'placeholder', \"children\": []}\n",
    "            newstring = \"\"\n",
    "            length = 0\n",
    "            notadded = False\n",
    "        elif length + len(currentReview) > max_length:\n",
    "            node['name'] = summary(newstring)\n",
    "            children.append(node)\n",
    "            node = {\"name\": 'placeholder', \"children\": [lst[count]]}\n",
    "            newstring = currentReview\n",
    "            length = len(currentReview)\n",
    "            notadded = False\n",
    "        else:\n",
    "            length += len(currentReview)\n",
    "            if len(newstring) == 0:\n",
    "                newstring = currentReview\n",
    "            else:\n",
    "                newstring += \" \" + currentReview\n",
    "            node[\"children\"].append(lst[count])\n",
    "            notadded = True\n",
    "    if len(children) == 0:\n",
    "        if len(node['children'])>1:\n",
    "            node['name'] = summary(newstring)\n",
    "            children.append(node)\n",
    "            if p:\n",
    "                print(\"RETURN TRUE\")\n",
    "            return children, True\n",
    "        if p:\n",
    "            print(\"RETURN FALSE\")\n",
    "        return lst, False\n",
    "    if notadded:\n",
    "        node['name'] = summary(newstring)\n",
    "        children.append(node)\n",
    "        if p:\n",
    "            print(\"RETURN TRUE\")\n",
    "    return children, True\n",
    "\n",
    "max_summary_length = 1500\n",
    "\n",
    "review_tree = build_review_tree(df.head(7000))\n",
    "temp_tree = review_tree.copy()\n",
    "json_string2 = json.dumps(review_tree, indent=2)\n",
    "for year_num in range(len(review_tree[\"children\"])):\n",
    "    for rating_num in range(len(review_tree[\"children\"][year_num]['children'])):\n",
    "        for topic_num in range(len(review_tree[\"children\"][year_num]['children'][rating_num]['children'])):\n",
    "            go_on = True\n",
    "            while go_on:\n",
    "                temp_tree[\"children\"][year_num]['children'][rating_num]['children'][topic_num]['children'], go_on = moreNodes(temp_tree[\"children\"][year_num]['children'][rating_num]['children'][topic_num]['children'],max_summary_length)\n",
    "\n",
    "\n",
    "# Convert to JSON format\n",
    "json_string = json.dumps(review_tree, indent=2)\n",
    "\n",
    "# Print the JSON structure\n",
    "print(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0b0b25-39a9-40dd-baf9-e96751a6de03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def count_leaf_nodes(node):\n",
    "    if \"children\" not in node:\n",
    "        return 1  # This is a leaf node\n",
    "\n",
    "    leaf_count = 0\n",
    "    for child in node[\"children\"]:\n",
    "        leaf_count += count_leaf_nodes(child)\n",
    "    return leaf_count\n",
    "def max_tree_depth(node):\n",
    "    if \"children\" not in node:\n",
    "        return 1  # This is a leaf node\n",
    "\n",
    "    max_depth = 0\n",
    "    for child in node.get(\"children\", []):\n",
    "        depth = max_tree_depth(child)\n",
    "        max_depth = max(max_depth, depth)\n",
    "\n",
    "    return max_depth + 1 \n",
    "\n",
    "\n",
    "leaf_count = count_leaf_nodes(temp_tree)\n",
    "print(\"Number of leaf nodes:\", leaf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b3ac85-2e4e-42d1-afba-d9a9b1aace32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "depth = max_tree_depth(temp_tree)\n",
    "print(\"Maximum depth of the tree:\", depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb9ca128-6b2e-4b81-8a4e-1b0a5044b00a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_descriptions(node):\n",
    "    new_node = {}\n",
    "    \n",
    "    if \"name\" in node:\n",
    "        newname = node['name'].split(\" \")\n",
    "        if len(node['name']) < 35:\n",
    "            new_node[\"name\"]  = node[\"name\"] \n",
    "        else:\n",
    "            new_node[\"name\"] = \" \".join(newname[:3]) + \".....\"\n",
    "            if len(new_node['name'])>35:\n",
    "                new_node[\"name\"] = node['name'][:30] + \".....\"\n",
    "        new_node[\"description\"] = node[\"name\"]\n",
    "    \n",
    "    if \"children\" in node:\n",
    "        new_children = []\n",
    "        for child in node[\"children\"]:\n",
    "            new_children.append(add_descriptions(child))\n",
    "        new_node[\"children\"] = new_children\n",
    "    \n",
    "    return new_node\n",
    "\n",
    "\n",
    "new_tree = add_descriptions(temp_tree)\n",
    "print(new_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71b90f27-9a58-4a8b-9405-380f115ce26a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_data = []\n",
    "def convert_to_df(node, parent_name=None):\n",
    "    global df_data\n",
    "    node_data = {\n",
    "        \"name\": node[\"name\"],\n",
    "        \"description\": node[\"description\"],\n",
    "        \"parent\": parent_name\n",
    "    }\n",
    "    children = node.get(\"children\", [])\n",
    "    for child in children:\n",
    "        convert_to_df(child, node[\"name\"])\n",
    "    df_data.append(node_data)\n",
    "\n",
    "\n",
    "convert_to_df(new_tree)\n",
    "df = pd.DataFrame(df_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"DataFrame:\")\n",
    "display(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a17e83d-5390-4326-a9b1-fe6a1a0e5b13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert JSON tree to DataFrame\n",
    "def convert_to_df(node, parent_name=None):\n",
    "    global df_data\n",
    "    node_data = {\n",
    "        \"name\": node[\"name\"],\n",
    "        \"description\": node[\"description\"],\n",
    "        \"parent\": parent_name\n",
    "    }\n",
    "    children = node.get(\"children\", [])\n",
    "    df_data.append(node_data)\n",
    "    for child in children:\n",
    "        convert_to_df(child, node[\"name\"])\n",
    "\n",
    "df_data = []\n",
    "convert_to_df(new_tree)\n",
    "df = pd.DataFrame(df_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"DataFrame:\")\n",
    "display(df)\n",
    "\n",
    "# Convert DataFrame back to JSON tree structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5f7e98-b696-481d-b7d2-8120dea29fb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_tree(data, parent_name=None):\n",
    "    children = []\n",
    "    for _, row in data.iterrows():\n",
    "        if row[\"parent\"] == parent_name:\n",
    "            child = {\n",
    "                \"name\": row[\"name\"],\n",
    "                \"description\": row[\"description\"]\n",
    "            }\n",
    "            child_children = build_tree(data, row[\"name\"])\n",
    "            if child_children:\n",
    "                child[\"children\"] = child_children\n",
    "            children.append(child)\n",
    "    return children\n",
    "\n",
    "converted_json_tree = build_tree(df)\n",
    "\n",
    "# Display the converted JSON tree\n",
    "print(\"\\nConverted JSON Tree:\")\n",
    "print(converted_json_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fa15ddd-5aff-4e56-a14f-70dccf33f459",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "LDA Topic Modeling (2)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
